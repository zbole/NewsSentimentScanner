import feedparser
import requests
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from urllib.parse import quote
import time

from datetime import datetime, timedelta
from email.utils import parsedate_to_datetime

# --- 1. é…ç½®åŒºåŸŸ ---
PUSH_TOKENS = [
    'eb50327c511447de8ec7b624d8d13c53',  # ç¬¬ä¸€ä¸ªäººçš„ Token
    'ä½ çš„_ç¬¬äºŒä¸ª_TOKEN_ç²˜è´´åœ¨è¿™é‡Œ'           # ç¬¬äºŒä¸ªäººçš„ Token
]

KEYWORDS = ["TSLA", "NVDA", "AAPL", "AMD", "GOOG", "GOOGL"]
CONFIDENCE_THRESHOLD = 0.85

# --- 2. åŠ è½½ FinBERT æ¨¡å‹ (ç¬¬ä¸€æ¬¡è¿è¡Œä¼šä¸‹è½½) ---
print("æ­£åœ¨åŠ è½½ FinBERT AI æ¨¡å‹ï¼Œè¯·ç¨å€™...")
# ä½¿ç”¨ä¸“é—¨é’ˆå¯¹é‡‘èæƒ…ç»ªå¾®è°ƒè¿‡çš„æ¨¡å‹
tokenizer = AutoTokenizer.from_pretrained("yiyanghkust/finbert-tone")
model = AutoModelForSequenceClassification.from_pretrained("yiyanghkust/finbert-tone")
labels = ['Neutral', 'Positive', 'Negative']  # æ³¨æ„ï¼šè¿™ä¸ªæ¨¡å‹çš„æ ‡ç­¾é¡ºåºé€šå¸¸æ˜¯è¿™æ ·ï¼Œä½†ä¹Ÿå¯èƒ½æ˜¯ [Neutral, Positive, Negative]ï¼Œä¸‹é¢é€»è¾‘å·²é€‚é…


# --- 3. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

def fetch_news(query):
    """ä» Google News RSS è·å–æ–°é—»"""
    encoded_query = quote(query)
    rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en"
    feed = feedparser.parse(rss_url)
    return feed.entries[:5]  # æ¯ä¸ªå…³é”®è¯åªå–æœ€æ–°çš„ 5 æ¡


def analyze_sentiment_finbert(text):
    """ä½¿ç”¨ FinBERT è¿›è¡Œ AI åˆ†æ"""
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)

    logits = outputs.logits
    probabilities = torch.softmax(logits, dim=1).numpy()[0]
    max_index = np.argmax(probabilities)

    sentiment = labels[max_index]
    confidence = probabilities[max_index]

    return sentiment, confidence


def send_wechat_alert(symbol, title, sentiment, confidence, link):
    """å‘é€å¾®ä¿¡æ¨é€ (æ”¯æŒå¤šè´¦å·)"""
    url = 'http://www.pushplus.plus/send'

    # --- 1. è®¡ç®—æ ‡é¢˜æ˜¾ç¤ºçš„ä¸­æ–‡æ–¹å‘ ---
    direction = ""  # é»˜è®¤å€¼
    emoji = "ğŸ˜"

    if sentiment == "Positive":
        direction = "åˆ©å¥½ğŸ”¥"
        emoji = "ğŸš€"
    elif sentiment == "Negative":
        direction = "åˆ©ç©ºâ„ï¸"
        emoji = "ğŸ”»"

    # --- 2. å‡†å¤‡æ­£æ–‡å†…å®¹ ---
    content = (
        f"### {emoji} {symbol} {direction}ä¿¡å·\n"
        f"- **æƒ…ç»ª**: {sentiment}\n"
        f"- **ç½®ä¿¡åº¦**: {confidence:.2f}\n"
        f"- **æ ‡é¢˜**: {title}\n"
        f"- **é“¾æ¥**: [ç‚¹å‡»æŸ¥çœ‹]({link})"
    )

    # --- 3. å¾ªç¯å‘é€ ---
    for token in PUSH_TOKENS:
        data = {
            "token": token,
            # [ä¿®æ”¹ç‚¹] è¿™é‡ŒæŠŠåŸæ¥çš„ "æƒ…ç»ªå¼‚åŠ¨" æ”¹æˆäº†åŠ¨æ€å˜é‡
            "title": f"{symbol} å‡ºç°{direction} ({confidence:.2f})",
            "content": content,
            "template": "markdown"
        }
        try:
            response = requests.post(url, json=data)
            # æ£€æŸ¥ä¸€ä¸‹å“åº”çŠ¶æ€
            resp_json = response.json()
            if resp_json.get('code') == 200:
                print(f"--> å·²æˆåŠŸæ¨é€åˆ° Token: ...{token[-4:]}")
            else:
                print(f"--> æ¨é€å¤±è´¥ (Token: ...{token[-4:]}): {resp_json.get('msg')}")
        except Exception as e:
            print(f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {e}")


def main():
    print(f"Github Action å¯åŠ¨: å¼€å§‹ç›‘æ§ {KEYWORDS}")
    print("-" * 30)

    # è®¾å®šä¸€ä¸ªæ—¶é—´çª—å£ï¼šåªçœ‹æœ€è¿‘ 4 å°æ—¶çš„æ–°é—» (é¿å…é‡å¤æ¨é€è€æ—§æ–°é—»)
    # å› ä¸º GitHub Actions æ¯æ¬¡è¿è¡Œéƒ½æ˜¯â€œå¤±å¿†â€çš„ï¼Œæ‰€ä»¥å¿…é¡»é æ—¶é—´æ¥è¿‡æ»¤
    time_threshold = datetime.now() - timedelta(minutes=40)

    for query in KEYWORDS:
        print(f"æ­£åœ¨æ‰«æ: {query} ...")
        try:
            articles = fetch_news(query)

            for item in articles:
                title = item.title
                link = item.link

                # --- æ–°å¢ï¼šæ—¶é—´è¿‡æ»¤é€»è¾‘ ---
                # Google News RSS çš„æ—¶é—´æ ¼å¼æ¯”è¾ƒå¤æ‚ï¼Œç”¨ parsedate_to_datetime è§£æ
                try:
                    pub_date = parsedate_to_datetime(item.published)
                    # æŠŠ pub_date è½¬æˆä¸å¸¦æ—¶åŒºçš„ timestamp è¿›è¡Œæ¯”è¾ƒï¼Œæˆ–è€…ç›´æ¥å¿½ç•¥æ—¶åŒº
                    if pub_date.replace(tzinfo=None) < time_threshold:
                        print(f"  [è·³è¿‡] æ–°é—»å¤ªæ—§: {title[:15]}...")
                        continue
                except Exception as e:
                    print(f"  æ—¶é—´è§£æå¤±è´¥ï¼Œé»˜è®¤å¤„ç†: {e}")

                # AI åˆ†æ
                sentiment, confidence = analyze_sentiment_finbert(title)

                print(f"[{query}] {sentiment} ({confidence:.2f}) - {title[:30]}...")

                # è¿‡æ»¤ç­–ç•¥ï¼šä¸æ˜¯ä¸­æ€§ ä¸” ç½®ä¿¡åº¦å¤Ÿé«˜
                if sentiment != 'Neutral' and confidence > CONFIDENCE_THRESHOLD:
                    send_wechat_alert(query, title, sentiment, confidence, link)

        except Exception as e:
            print(f"æŠ“å–é”™è¯¯: {e}")

    print("æœ¬æ¬¡æ‰«æç»“æŸï¼Œè„šæœ¬è‡ªåŠ¨é€€å‡º (ç­‰å¾…ä¸‹ä¸€æ¬¡ Cron å”¤é†’)")


if __name__ == "__main__":
    main()
